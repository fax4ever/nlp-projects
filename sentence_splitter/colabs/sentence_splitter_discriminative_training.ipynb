{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3ab06da8",
   "metadata": {},
   "source": [
    "# Sentence Splitter: Training\n",
    "\n",
    "## Embedding Models Fine-Tuning\n",
    "\n",
    "In this notebook, we're going to fine-tune different (actually 6) embedding models for sentence splitting,\n",
    "using the train and the validation sets provided by the homework assignment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7769ceb5",
   "metadata": {},
   "source": [
    "Install the libraries in the local virtual environment. \n",
    "We use specific versions to enforce reproducibility for this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ceba93cf-d562-40aa-9e77-b826fe0b3045",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in /opt/app-root/lib64/python3.11/site-packages (25.2)\n",
      "Requirement already satisfied: torch==2.7.0 in /opt/app-root/lib64/python3.11/site-packages (2.7.0)\n",
      "Requirement already satisfied: numpy==2.3.2 in /opt/app-root/lib64/python3.11/site-packages (2.3.2)\n",
      "Requirement already satisfied: pandas==2.3.2 in /opt/app-root/lib64/python3.11/site-packages (2.3.2)\n",
      "Requirement already satisfied: datasets==3.6.0 in /opt/app-root/lib64/python3.11/site-packages (3.6.0)\n",
      "Requirement already satisfied: jupyter==1.1.1 in /opt/app-root/lib64/python3.11/site-packages (1.1.1)\n",
      "Requirement already satisfied: transformers==4.56.1 in /opt/app-root/lib64/python3.11/site-packages (from transformers[torch]==4.56.1) (4.56.1)\n",
      "Requirement already satisfied: evaluate==0.4.5 in /opt/app-root/lib64/python3.11/site-packages (0.4.5)\n",
      "Requirement already satisfied: filelock in /opt/app-root/lib64/python3.11/site-packages (from torch==2.7.0) (3.19.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /opt/app-root/lib64/python3.11/site-packages (from torch==2.7.0) (4.14.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /opt/app-root/lib64/python3.11/site-packages (from torch==2.7.0) (1.14.0)\n",
      "Requirement already satisfied: networkx in /opt/app-root/lib64/python3.11/site-packages (from torch==2.7.0) (3.5)\n",
      "Requirement already satisfied: jinja2 in /opt/app-root/lib64/python3.11/site-packages (from torch==2.7.0) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /opt/app-root/lib64/python3.11/site-packages (from torch==2.7.0) (2025.3.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /opt/app-root/lib64/python3.11/site-packages (from torch==2.7.0) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /opt/app-root/lib64/python3.11/site-packages (from torch==2.7.0) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /opt/app-root/lib64/python3.11/site-packages (from torch==2.7.0) (12.6.80)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.5.1.17 in /opt/app-root/lib64/python3.11/site-packages (from torch==2.7.0) (9.5.1.17)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /opt/app-root/lib64/python3.11/site-packages (from torch==2.7.0) (12.6.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /opt/app-root/lib64/python3.11/site-packages (from torch==2.7.0) (11.3.0.4)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /opt/app-root/lib64/python3.11/site-packages (from torch==2.7.0) (10.3.7.77)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /opt/app-root/lib64/python3.11/site-packages (from torch==2.7.0) (11.7.1.2)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /opt/app-root/lib64/python3.11/site-packages (from torch==2.7.0) (12.5.4.2)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.3 in /opt/app-root/lib64/python3.11/site-packages (from torch==2.7.0) (0.6.3)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.26.2 in /opt/app-root/lib64/python3.11/site-packages (from torch==2.7.0) (2.26.2)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /opt/app-root/lib64/python3.11/site-packages (from torch==2.7.0) (12.6.77)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /opt/app-root/lib64/python3.11/site-packages (from torch==2.7.0) (12.6.85)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /opt/app-root/lib64/python3.11/site-packages (from torch==2.7.0) (1.11.1.6)\n",
      "Requirement already satisfied: triton==3.3.0 in /opt/app-root/lib64/python3.11/site-packages (from torch==2.7.0) (3.3.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/app-root/lib64/python3.11/site-packages (from pandas==2.3.2) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/app-root/lib64/python3.11/site-packages (from pandas==2.3.2) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/app-root/lib64/python3.11/site-packages (from pandas==2.3.2) (2025.2)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /opt/app-root/lib64/python3.11/site-packages (from datasets==3.6.0) (21.0.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/app-root/lib64/python3.11/site-packages (from datasets==3.6.0) (0.3.8)\n",
      "Requirement already satisfied: requests>=2.32.2 in /opt/app-root/lib64/python3.11/site-packages (from datasets==3.6.0) (2.32.4)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in /opt/app-root/lib64/python3.11/site-packages (from datasets==3.6.0) (4.67.1)\n",
      "Requirement already satisfied: xxhash in /opt/app-root/lib64/python3.11/site-packages (from datasets==3.6.0) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /opt/app-root/lib64/python3.11/site-packages (from datasets==3.6.0) (0.70.16)\n",
      "Requirement already satisfied: huggingface-hub>=0.24.0 in /opt/app-root/lib64/python3.11/site-packages (from datasets==3.6.0) (0.34.4)\n",
      "Requirement already satisfied: packaging in /opt/app-root/lib64/python3.11/site-packages (from datasets==3.6.0) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/app-root/lib64/python3.11/site-packages (from datasets==3.6.0) (6.0.2)\n",
      "Requirement already satisfied: notebook in /opt/app-root/lib64/python3.11/site-packages (from jupyter==1.1.1) (7.4.5)\n",
      "Requirement already satisfied: jupyter-console in /opt/app-root/lib64/python3.11/site-packages (from jupyter==1.1.1) (6.6.3)\n",
      "Requirement already satisfied: nbconvert in /opt/app-root/lib64/python3.11/site-packages (from jupyter==1.1.1) (7.16.6)\n",
      "Requirement already satisfied: ipykernel in /opt/app-root/lib64/python3.11/site-packages (from jupyter==1.1.1) (6.29.5)\n",
      "Requirement already satisfied: ipywidgets in /opt/app-root/lib64/python3.11/site-packages (from jupyter==1.1.1) (8.1.7)\n",
      "Requirement already satisfied: jupyterlab in /opt/app-root/lib64/python3.11/site-packages (from jupyter==1.1.1) (4.4.7)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/app-root/lib64/python3.11/site-packages (from transformers==4.56.1->transformers[torch]==4.56.1) (2025.9.1)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /opt/app-root/lib64/python3.11/site-packages (from transformers==4.56.1->transformers[torch]==4.56.1) (0.22.0)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /opt/app-root/lib64/python3.11/site-packages (from transformers==4.56.1->transformers[torch]==4.56.1) (0.6.2)\n",
      "Requirement already satisfied: accelerate>=0.26.0 in /opt/app-root/lib64/python3.11/site-packages (from transformers[torch]==4.56.1) (1.10.1)\n",
      "Requirement already satisfied: setuptools>=40.8.0 in /opt/app-root/lib64/python3.11/site-packages (from triton==3.3.0->torch==2.7.0) (75.8.2)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /opt/app-root/lib64/python3.11/site-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets==3.6.0) (3.12.13)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /opt/app-root/lib64/python3.11/site-packages (from huggingface-hub>=0.24.0->datasets==3.6.0) (1.1.9)\n",
      "Requirement already satisfied: psutil in /opt/app-root/lib64/python3.11/site-packages (from accelerate>=0.26.0->transformers[torch]==4.56.1) (7.0.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /opt/app-root/lib64/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets==3.6.0) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/app-root/lib64/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets==3.6.0) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/app-root/lib64/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets==3.6.0) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/app-root/lib64/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets==3.6.0) (1.7.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/app-root/lib64/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets==3.6.0) (6.5.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /opt/app-root/lib64/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets==3.6.0) (0.3.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /opt/app-root/lib64/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets==3.6.0) (1.20.1)\n",
      "Requirement already satisfied: idna>=2.0 in /opt/app-root/lib64/python3.11/site-packages (from yarl<2.0,>=1.17.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets==3.6.0) (3.10)\n",
      "Requirement already satisfied: six>=1.5 in /opt/app-root/lib64/python3.11/site-packages (from python-dateutil>=2.8.2->pandas==2.3.2) (1.17.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/app-root/lib64/python3.11/site-packages (from requests>=2.32.2->datasets==3.6.0) (3.4.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/app-root/lib64/python3.11/site-packages (from requests>=2.32.2->datasets==3.6.0) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/app-root/lib64/python3.11/site-packages (from requests>=2.32.2->datasets==3.6.0) (2025.6.15)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/app-root/lib64/python3.11/site-packages (from sympy>=1.13.3->torch==2.7.0) (1.3.0)\n",
      "Requirement already satisfied: comm>=0.1.1 in /opt/app-root/lib64/python3.11/site-packages (from ipykernel->jupyter==1.1.1) (0.2.2)\n",
      "Requirement already satisfied: debugpy>=1.6.5 in /opt/app-root/lib64/python3.11/site-packages (from ipykernel->jupyter==1.1.1) (1.8.14)\n",
      "Requirement already satisfied: ipython>=7.23.1 in /opt/app-root/lib64/python3.11/site-packages (from ipykernel->jupyter==1.1.1) (9.3.0)\n",
      "Requirement already satisfied: jupyter-client>=6.1.12 in /opt/app-root/lib64/python3.11/site-packages (from ipykernel->jupyter==1.1.1) (8.6.3)\n",
      "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in /opt/app-root/lib64/python3.11/site-packages (from ipykernel->jupyter==1.1.1) (5.8.1)\n",
      "Requirement already satisfied: matplotlib-inline>=0.1 in /opt/app-root/lib64/python3.11/site-packages (from ipykernel->jupyter==1.1.1) (0.1.7)\n",
      "Requirement already satisfied: nest-asyncio in /opt/app-root/lib64/python3.11/site-packages (from ipykernel->jupyter==1.1.1) (1.6.0)\n",
      "Requirement already satisfied: pyzmq>=24 in /opt/app-root/lib64/python3.11/site-packages (from ipykernel->jupyter==1.1.1) (27.0.0)\n",
      "Requirement already satisfied: tornado>=6.1 in /opt/app-root/lib64/python3.11/site-packages (from ipykernel->jupyter==1.1.1) (6.5.1)\n",
      "Requirement already satisfied: traitlets>=5.4.0 in /opt/app-root/lib64/python3.11/site-packages (from ipykernel->jupyter==1.1.1) (5.14.3)\n",
      "Requirement already satisfied: decorator in /opt/app-root/lib64/python3.11/site-packages (from ipython>=7.23.1->ipykernel->jupyter==1.1.1) (5.2.1)\n",
      "Requirement already satisfied: ipython-pygments-lexers in /opt/app-root/lib64/python3.11/site-packages (from ipython>=7.23.1->ipykernel->jupyter==1.1.1) (1.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in /opt/app-root/lib64/python3.11/site-packages (from ipython>=7.23.1->ipykernel->jupyter==1.1.1) (0.19.2)\n",
      "Requirement already satisfied: pexpect>4.3 in /opt/app-root/lib64/python3.11/site-packages (from ipython>=7.23.1->ipykernel->jupyter==1.1.1) (4.9.0)\n",
      "Requirement already satisfied: prompt_toolkit<3.1.0,>=3.0.41 in /opt/app-root/lib64/python3.11/site-packages (from ipython>=7.23.1->ipykernel->jupyter==1.1.1) (3.0.51)\n",
      "Requirement already satisfied: pygments>=2.4.0 in /opt/app-root/lib64/python3.11/site-packages (from ipython>=7.23.1->ipykernel->jupyter==1.1.1) (2.19.1)\n",
      "Requirement already satisfied: stack_data in /opt/app-root/lib64/python3.11/site-packages (from ipython>=7.23.1->ipykernel->jupyter==1.1.1) (0.6.3)\n",
      "Requirement already satisfied: wcwidth in /opt/app-root/lib64/python3.11/site-packages (from prompt_toolkit<3.1.0,>=3.0.41->ipython>=7.23.1->ipykernel->jupyter==1.1.1) (0.2.13)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /opt/app-root/lib64/python3.11/site-packages (from jedi>=0.16->ipython>=7.23.1->ipykernel->jupyter==1.1.1) (0.8.4)\n",
      "Requirement already satisfied: platformdirs>=2.5 in /opt/app-root/lib64/python3.11/site-packages (from jupyter-core!=5.0.*,>=4.12->ipykernel->jupyter==1.1.1) (4.3.8)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /opt/app-root/lib64/python3.11/site-packages (from pexpect>4.3->ipython>=7.23.1->ipykernel->jupyter==1.1.1) (0.7.0)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0.14 in /opt/app-root/lib64/python3.11/site-packages (from ipywidgets->jupyter==1.1.1) (4.0.14)\n",
      "Requirement already satisfied: jupyterlab_widgets~=3.0.15 in /opt/app-root/lib64/python3.11/site-packages (from ipywidgets->jupyter==1.1.1) (3.0.15)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/app-root/lib64/python3.11/site-packages (from jinja2->torch==2.7.0) (3.0.2)\n",
      "Requirement already satisfied: async-lru>=1.0.0 in /opt/app-root/lib64/python3.11/site-packages (from jupyterlab->jupyter==1.1.1) (2.0.5)\n",
      "Requirement already satisfied: httpx<1,>=0.25.0 in /opt/app-root/lib64/python3.11/site-packages (from jupyterlab->jupyter==1.1.1) (0.28.1)\n",
      "Requirement already satisfied: jupyter-lsp>=2.0.0 in /opt/app-root/lib64/python3.11/site-packages (from jupyterlab->jupyter==1.1.1) (2.2.5)\n",
      "Requirement already satisfied: jupyter-server<3,>=2.4.0 in /opt/app-root/lib64/python3.11/site-packages (from jupyterlab->jupyter==1.1.1) (2.15.0)\n",
      "Requirement already satisfied: jupyterlab-server<3,>=2.27.1 in /opt/app-root/lib64/python3.11/site-packages (from jupyterlab->jupyter==1.1.1) (2.27.3)\n",
      "Requirement already satisfied: notebook-shim>=0.2 in /opt/app-root/lib64/python3.11/site-packages (from jupyterlab->jupyter==1.1.1) (0.2.4)\n",
      "Requirement already satisfied: anyio in /opt/app-root/lib64/python3.11/site-packages (from httpx<1,>=0.25.0->jupyterlab->jupyter==1.1.1) (4.9.0)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/app-root/lib64/python3.11/site-packages (from httpx<1,>=0.25.0->jupyterlab->jupyter==1.1.1) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /opt/app-root/lib64/python3.11/site-packages (from httpcore==1.*->httpx<1,>=0.25.0->jupyterlab->jupyter==1.1.1) (0.16.0)\n",
      "Requirement already satisfied: argon2-cffi>=21.1 in /opt/app-root/lib64/python3.11/site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter==1.1.1) (25.1.0)\n",
      "Requirement already satisfied: jupyter-events>=0.11.0 in /opt/app-root/lib64/python3.11/site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter==1.1.1) (0.12.0)\n",
      "Requirement already satisfied: jupyter-server-terminals>=0.4.4 in /opt/app-root/lib64/python3.11/site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter==1.1.1) (0.5.3)\n",
      "Requirement already satisfied: nbformat>=5.3.0 in /opt/app-root/lib64/python3.11/site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter==1.1.1) (5.10.4)\n",
      "Requirement already satisfied: overrides>=5.0 in /opt/app-root/lib64/python3.11/site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter==1.1.1) (7.7.0)\n",
      "Requirement already satisfied: prometheus-client>=0.9 in /opt/app-root/lib64/python3.11/site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter==1.1.1) (0.22.1)\n",
      "Requirement already satisfied: send2trash>=1.8.2 in /opt/app-root/lib64/python3.11/site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter==1.1.1) (1.8.3)\n",
      "Requirement already satisfied: terminado>=0.8.3 in /opt/app-root/lib64/python3.11/site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter==1.1.1) (0.18.1)\n",
      "Requirement already satisfied: websocket-client>=1.7 in /opt/app-root/lib64/python3.11/site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter==1.1.1) (1.8.0)\n",
      "Requirement already satisfied: babel>=2.10 in /opt/app-root/lib64/python3.11/site-packages (from jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter==1.1.1) (2.17.0)\n",
      "Requirement already satisfied: json5>=0.9.0 in /opt/app-root/lib64/python3.11/site-packages (from jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter==1.1.1) (0.12.0)\n",
      "Requirement already satisfied: jsonschema>=4.18.0 in /opt/app-root/lib64/python3.11/site-packages (from jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter==1.1.1) (4.24.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in /opt/app-root/lib64/python3.11/site-packages (from anyio->httpx<1,>=0.25.0->jupyterlab->jupyter==1.1.1) (1.3.1)\n",
      "Requirement already satisfied: argon2-cffi-bindings in /opt/app-root/lib64/python3.11/site-packages (from argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->jupyterlab->jupyter==1.1.1) (21.2.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /opt/app-root/lib64/python3.11/site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter==1.1.1) (2025.4.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /opt/app-root/lib64/python3.11/site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter==1.1.1) (0.36.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /opt/app-root/lib64/python3.11/site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter==1.1.1) (0.25.1)\n",
      "Requirement already satisfied: python-json-logger>=2.0.4 in /opt/app-root/lib64/python3.11/site-packages (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter==1.1.1) (3.3.0)\n",
      "Requirement already satisfied: rfc3339-validator in /opt/app-root/lib64/python3.11/site-packages (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter==1.1.1) (0.1.4)\n",
      "Requirement already satisfied: rfc3986-validator>=0.1.1 in /opt/app-root/lib64/python3.11/site-packages (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter==1.1.1) (0.1.1)\n",
      "Requirement already satisfied: fqdn in /opt/app-root/lib64/python3.11/site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter==1.1.1) (1.5.1)\n",
      "Requirement already satisfied: isoduration in /opt/app-root/lib64/python3.11/site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter==1.1.1) (20.11.0)\n",
      "Requirement already satisfied: jsonpointer>1.13 in /opt/app-root/lib64/python3.11/site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter==1.1.1) (3.0.0)\n",
      "Requirement already satisfied: uri-template in /opt/app-root/lib64/python3.11/site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter==1.1.1) (1.3.0)\n",
      "Requirement already satisfied: webcolors>=24.6.0 in /opt/app-root/lib64/python3.11/site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter==1.1.1) (24.11.1)\n",
      "Requirement already satisfied: beautifulsoup4 in /opt/app-root/lib64/python3.11/site-packages (from nbconvert->jupyter==1.1.1) (4.13.4)\n",
      "Requirement already satisfied: bleach!=5.0.0 in /opt/app-root/lib64/python3.11/site-packages (from bleach[css]!=5.0.0->nbconvert->jupyter==1.1.1) (6.2.0)\n",
      "Requirement already satisfied: defusedxml in /opt/app-root/lib64/python3.11/site-packages (from nbconvert->jupyter==1.1.1) (0.7.1)\n",
      "Requirement already satisfied: jupyterlab-pygments in /opt/app-root/lib64/python3.11/site-packages (from nbconvert->jupyter==1.1.1) (0.3.0)\n",
      "Requirement already satisfied: mistune<4,>=2.0.3 in /opt/app-root/lib64/python3.11/site-packages (from nbconvert->jupyter==1.1.1) (3.1.3)\n",
      "Requirement already satisfied: nbclient>=0.5.0 in /opt/app-root/lib64/python3.11/site-packages (from nbconvert->jupyter==1.1.1) (0.10.2)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in /opt/app-root/lib64/python3.11/site-packages (from nbconvert->jupyter==1.1.1) (1.5.1)\n",
      "Requirement already satisfied: webencodings in /opt/app-root/lib64/python3.11/site-packages (from bleach!=5.0.0->bleach[css]!=5.0.0->nbconvert->jupyter==1.1.1) (0.5.1)\n",
      "Requirement already satisfied: tinycss2<1.5,>=1.1.0 in /opt/app-root/lib64/python3.11/site-packages (from bleach[css]!=5.0.0->nbconvert->jupyter==1.1.1) (1.4.0)\n",
      "Requirement already satisfied: fastjsonschema>=2.15 in /opt/app-root/lib64/python3.11/site-packages (from nbformat>=5.3.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter==1.1.1) (2.21.1)\n",
      "Requirement already satisfied: cffi>=1.0.1 in /opt/app-root/lib64/python3.11/site-packages (from argon2-cffi-bindings->argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->jupyterlab->jupyter==1.1.1) (1.17.1)\n",
      "Requirement already satisfied: pycparser in /opt/app-root/lib64/python3.11/site-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->jupyterlab->jupyter==1.1.1) (2.22)\n",
      "Requirement already satisfied: soupsieve>1.2 in /opt/app-root/lib64/python3.11/site-packages (from beautifulsoup4->nbconvert->jupyter==1.1.1) (2.7)\n",
      "Requirement already satisfied: arrow>=0.15.0 in /opt/app-root/lib64/python3.11/site-packages (from isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter==1.1.1) (1.3.0)\n",
      "Requirement already satisfied: types-python-dateutil>=2.8.10 in /opt/app-root/lib64/python3.11/site-packages (from arrow>=0.15.0->isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter==1.1.1) (2.9.0.20250516)\n",
      "Requirement already satisfied: executing>=1.2.0 in /opt/app-root/lib64/python3.11/site-packages (from stack_data->ipython>=7.23.1->ipykernel->jupyter==1.1.1) (2.2.0)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /opt/app-root/lib64/python3.11/site-packages (from stack_data->ipython>=7.23.1->ipykernel->jupyter==1.1.1) (3.0.0)\n",
      "Requirement already satisfied: pure-eval in /opt/app-root/lib64/python3.11/site-packages (from stack_data->ipython>=7.23.1->ipykernel->jupyter==1.1.1) (0.2.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade pip\n",
    "!pip install torch==2.7.0 numpy==2.3.2 pandas==2.3.2 datasets==3.6.0 jupyter==1.1.1 transformers[torch]==4.56.1 evaluate==0.4.5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ffd513f",
   "metadata": {},
   "source": [
    "Import all required libraries for the training. \n",
    "We do this first to fail fast in case additional packages need to be installed in the virtual environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b1f0e909-635d-4953-b6f0-1db100b79730",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from datasets import Dataset, DatasetDict, load_dataset\n",
    "from transformers import (AutoTokenizer, AutoModelForTokenClassification, DataCollatorForTokenClassification, \n",
    "                          TrainingArguments, Trainer, pipeline)\n",
    "from typing import Union, Any, Optional\n",
    "import evaluate\n",
    "from typing import Iterable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6713e6e",
   "metadata": {},
   "source": [
    "Optionally (not required to run the notebook). If you want to push the fine-tuned model to the registry, you need to set the token.\n",
    "\n",
    "Verify that a hardware accelerator is available. This notebook requires a GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "48b4a80d-c9a5-4949-b7d0-6dac672c45bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# os.environ['HF_TOKEN'] = 'PUT_YOUR_TOKEN_HERE'\n",
    "\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "839d5b93",
   "metadata": {},
   "source": [
    "Set up deterministic behavior for reproducible results by configuring random seeds for all relevant libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a0c03d87",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed=777, total_determinism=False):\n",
    "    seed = seed\n",
    "    torch.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    if total_determinism:\n",
    "        torch.use_deterministic_algorithms(True)\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "set_seed() # Set the seed for reproducibility -- use_deterministic_algorithms can make training slower :("
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22155736",
   "metadata": {},
   "source": [
    "### Data Preparation and Alignment\n",
    "\n",
    "In this section, we create a standard Hugging Face dataset from the CSV files: `data/manzoni_dev_tokens.csv` and `data/manzoni_train_tokens.csv`.\n",
    "\n",
    "The output will be available at [fax4ever/manzoni-192](https://huggingface.co/datasets/fax4ever/manzoni-192).\n",
    "\n",
    "The original CSV files contain text that must be split into portions that can be passed to the encoder model. Typically, the maximum number of tokens for encoder models is 512 (e.g., BERT).\n",
    "Since each word can produce one or more tokens, a simple strategy would be to split texts to use the maximum number of tokens. This is not always optimal.\n",
    "Therefore, the number of words per input becomes our first hyperparameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "357c61f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "SIZE = 192 # Number of words to put on each input of the encoder model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "737f2acb",
   "metadata": {},
   "source": [
    "In the following code, we create the dataset and push it to the Hub.\n",
    "\n",
    "Publishing to the Hugging Face Hub allows us to use standard APIs—one benefit of open standards."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8daa7d2e-00af-41b7-b24f-99065b5b59e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 389 sequences of 192 tokens each\n",
      "Validation: 48 sequences of 192 tokens each\n"
     ]
    }
   ],
   "source": [
    "def group_into_sequences(df, seq_len=SIZE):\n",
    "    tokens = df['token'].tolist()\n",
    "    labels = df['label'].tolist()\n",
    "    \n",
    "    # Group into sequences of seq_len\n",
    "    token_seqs = [tokens[i:i+seq_len] for i in range(0, len(tokens), seq_len) if len(tokens[i:i+seq_len]) == seq_len]\n",
    "    label_seqs = [labels[i:i+seq_len] for i in range(0, len(labels), seq_len) if len(labels[i:i+seq_len]) == seq_len]\n",
    "    \n",
    "    return {'tokens': token_seqs, 'labels': label_seqs}\n",
    "\n",
    "\n",
    "train = pd.read_csv(\"../data/manzoni_train_tokens.csv\")  # token,label\n",
    "validation = pd.read_csv(\"../data/manzoni_dev_tokens.csv\")  # token,label\n",
    "\n",
    "# Group into sequences of SIZE\n",
    "train_grouped = group_into_sequences(train)\n",
    "validation_grouped = group_into_sequences(validation)\n",
    "\n",
    "print(f\"Train: {len(train_grouped['tokens'])} sequences of {SIZE} tokens each\")\n",
    "print(f\"Validation: {len(validation_grouped['tokens'])} sequences of {SIZE} tokens each\")\n",
    "\n",
    "train_dataset = Dataset.from_dict(train_grouped)\n",
    "validation_dataset = Dataset.from_dict(validation_grouped)\n",
    "\n",
    "dataset_dict = DatasetDict({\n",
    "    'train': train_dataset,\n",
    "    'validation': validation_dataset  # Using 'validation' as the standard name\n",
    "})\n",
    "\n",
    "# Optionally publish the dataset to the hub\n",
    "# dataset_dict.push_to_hub(f\"fax4ever/manzoni-{SIZE}\", token=os.getenv(\"HF_TOKEN\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4a56efa",
   "metadata": {},
   "source": [
    "Alternatively, simply load the dataset from Hugging Face:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a7c18589",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dict = load_dataset(f\"fax4ever/manzoni-{SIZE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9e4cce7",
   "metadata": {},
   "source": [
    "During tokenization, each word in an input may become one or more tokens.\n",
    "First, define some constants to reflect the convention in the CSV files. A label of 1 denotes the end (and thus beginning of a new sentence); 0 is used otherwise. Special tokens denoting start and end of sequences are labeled with 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5affc173",
   "metadata": {},
   "outputs": [],
   "source": [
    "END_OF_SENTENCE = 1\n",
    "NOT_END_OF_SENTENCE = 0\n",
    "LABEL_FOR_START_END_OF_SEQUENCE = NOT_END_OF_SENTENCE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "428c79d8",
   "metadata": {},
   "source": [
    "Choose a base embedding model to classify tokens as 0 or 1 (`num_labels=2`).\n",
    "\n",
    "Since the dataset is in Italian, consider multilingual models or models trained on Italian corpora:\n",
    "\n",
    "1. 🚀 ModernBERT-base-ita (most recent – Dec 2024)\n",
    "   - `DeepMount00/ModernBERT-base-ita`\n",
    "\n",
    "2. 🇮🇹 Italian BERT XXL (most established)\n",
    "   - `dbmdz/bert-base-italian-xxl-cased`\n",
    "\n",
    "3. 🌍 XLM-RoBERTa (best multilingual)\n",
    "   - `FacebookAI/xlm-roberta-base`\n",
    "   - `FacebookAI/xlm-roberta-large`\n",
    "\n",
    "4. 🔬 Italian ELECTRA (alternative architecture)\n",
    "   - `dbmdz/electra-base-italian-xxl-cased-discriminator`\n",
    "\n",
    "Because we classify tokens rather than whole sequences, we use `AutoModelForTokenClassification` instead of `AutoModelForSequenceClassification`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0d120457",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of ModernBertForTokenClassification were not initialized from the model checkpoint at DeepMount00/ModernBERT-base-ita and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "EMBEDDING_MODEL = \"DeepMount00/ModernBERT-base-ita\"\n",
    "MODEL_NAME = \"ModernBERT-base-ita\"\n",
    "\n",
    "model = AutoModelForTokenClassification.from_pretrained(EMBEDDING_MODEL, num_labels=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "049da04b",
   "metadata": {},
   "source": [
    "The original dataset provides labels for each word. When we tokenize the texts, we need to align the labels to the generated tokens.\n",
    "We keep label 1 for the first token of any word labeled 1 and use 0 for all other tokens. This preserves the original count of 1s per input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1ab24b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(EMBEDDING_MODEL)\n",
    "\n",
    "def tokenize_and_align_labels(items):\n",
    "    tokenized_inputs = tokenizer(\n",
    "        items[\"tokens\"], is_split_into_words=True\n",
    "    )\n",
    "\n",
    "    all_labels = items[\"labels\"]\n",
    "    new_labels = []\n",
    "    for i, labels in enumerate(all_labels):\n",
    "        word_ids = tokenized_inputs.word_ids(i)\n",
    "        new_labels.append(align_labels_with_tokens(labels, word_ids))\n",
    "\n",
    "    tokenized_inputs[\"labels\"] = new_labels\n",
    "    return tokenized_inputs\n",
    "\n",
    "def align_labels_with_tokens(labels, word_ids):\n",
    "    new_labels = []\n",
    "    current_word = None\n",
    "    for word_id in word_ids:\n",
    "        if word_id != current_word:\n",
    "            # Start of a new word!\n",
    "            current_word = word_id\n",
    "            label = LABEL_FOR_START_END_OF_SEQUENCE if word_id is None else labels[word_id]\n",
    "            new_labels.append(label)\n",
    "        else:\n",
    "            # Treat the same word never as end of sentence\n",
    "            new_labels.append(NOT_END_OF_SENTENCE)\n",
    "    return new_labels\n",
    "\n",
    "tokenized_dataset_dict = dataset_dict.map(\n",
    "    tokenize_and_align_labels,\n",
    "    batched=True,\n",
    "    remove_columns=dataset_dict[\"train\"].column_names,\n",
    "    batch_size=128,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0741f4c7",
   "metadata": {},
   "source": [
    "### Training\n",
    "\n",
    "The dataset is highly imbalanced: most labels are 0 and few are 1. Accuracy is not a suitable metric here—for example, predicting only 0 yields high accuracy.\n",
    "\n",
    "We therefore select the best model based on F1 score on the validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f87d34bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# as naming convention we use the embedding model name + \"-sentence-splitter\"\n",
    "# in this way we can easily identify the model we used to train the sentence splitter\n",
    "trained_model_name = MODEL_NAME + \"-sentence-splitter\"\n",
    "\n",
    "training_arguments = TrainingArguments(\n",
    "    trained_model_name,\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    num_train_epochs=30,\n",
    "    weight_decay=0.01,\n",
    "    # Optionally, push to the hub the fine-tuned model\n",
    "    # push_to_hub=True,\n",
    "    # hub_token=os.environ['HF_TOKEN'],\n",
    "    load_best_model_at_end=True, # Stop training when F1 stops improving\n",
    "    metric_for_best_model=\"f1\" # Of course on the validation set\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4e8b113",
   "metadata": {},
   "source": [
    "We also use a weighted cross‑entropy loss during training.\n",
    "Misclassifying class 1 (end of sentence) is penalized 30× more than class 0. The weight (30) is another hyperparameter, motivated by the label distribution (≈96.7% class 0 vs ≈3.3% class 1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a83162fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WeightedTrainer(Trainer):\n",
    "    def compute_loss(self, model: nn.Module, inputs: dict[str, Union[torch.Tensor, Any]], return_outputs: bool = False, num_items_in_batch: Optional[torch.Tensor] = None):\n",
    "        labels = inputs.pop(\"labels\")\n",
    "        # forward pass\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.get(\"logits\")\n",
    "        # compute custom loss for 2 labels with different weights\n",
    "        # Simple class weights: give sentence endings 30x more importance\n",
    "        # Based on your data: 96.7% class 0, 3.3% class 1 → ~30:1 ratio\n",
    "        loss_fct = nn.CrossEntropyLoss(weight=torch.tensor([1.0, 30.0], device=model.device))\n",
    "        loss = loss_fct(logits.view(-1, self.model.config.num_labels), labels.view(-1))\n",
    "        if num_items_in_batch is not None:\n",
    "            loss = loss / num_items_in_batch\n",
    "        return (loss, outputs) if return_outputs else loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7f53b9f",
   "metadata": {},
   "source": [
    "For each epoch, compute F1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1d7b2734",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_f1_metric(predictions: Iterable[Iterable], references: Iterable[Iterable]) -> float:\n",
    "    metric = evaluate.load(\"f1\", average=\"binary\")\n",
    "\n",
    "    assert len(predictions) == len(references)\n",
    "    for i, prediction_batch in enumerate(predictions):\n",
    "        reference_batch = references[i]\n",
    "        \n",
    "        prediction_valid_batch = []\n",
    "        reference_valid_batch = []\n",
    "        trailing = False\n",
    "\n",
    "        assert len(prediction_batch) == len(reference_batch)\n",
    "        for prediction, reference in zip(prediction_batch, reference_batch):\n",
    "            if reference == -100 or reference == '-100':\n",
    "                trailing = True\n",
    "                continue\n",
    "            else:\n",
    "                assert not trailing\n",
    "                reference_valid_batch.append(reference)\n",
    "                prediction_valid_batch.append(prediction)\n",
    "\n",
    "        metric.add_batch(predictions=prediction_valid_batch, references=reference_valid_batch)\n",
    "    return metric.compute()\n",
    "\n",
    "def compute_metrics(eval_preds):\n",
    "    logits, labels = eval_preds\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "\n",
    "    return compute_f1_metric(predictions=predictions, references=labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9fdba42",
   "metadata": {},
   "source": [
    "Push all epoch metrics and the final trained model to the Hugging Face Hub so the model can be used for inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5a290771",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'eos_token_id': None, 'bos_token_id': None}.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1470' max='1470' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1470/1470 16:32, Epoch 30/30]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.008159</td>\n",
       "      <td>0.962179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.004240</td>\n",
       "      <td>0.969605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.004161</td>\n",
       "      <td>0.978528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.003743</td>\n",
       "      <td>0.989147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.003536</td>\n",
       "      <td>0.987616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.002984</td>\n",
       "      <td>0.989147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.005790</td>\n",
       "      <td>0.990683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.009161</td>\n",
       "      <td>0.989114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.009182</td>\n",
       "      <td>0.990654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.009585</td>\n",
       "      <td>0.990654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.009900</td>\n",
       "      <td>0.009662</td>\n",
       "      <td>0.990654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.009900</td>\n",
       "      <td>0.008159</td>\n",
       "      <td>0.992224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.009900</td>\n",
       "      <td>0.007403</td>\n",
       "      <td>0.992224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.009900</td>\n",
       "      <td>0.008102</td>\n",
       "      <td>0.992224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.009900</td>\n",
       "      <td>0.008229</td>\n",
       "      <td>0.992224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.009900</td>\n",
       "      <td>0.008384</td>\n",
       "      <td>0.992224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.009900</td>\n",
       "      <td>0.008467</td>\n",
       "      <td>0.992224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.009900</td>\n",
       "      <td>0.008601</td>\n",
       "      <td>0.992224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.009900</td>\n",
       "      <td>0.008722</td>\n",
       "      <td>0.992224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.009900</td>\n",
       "      <td>0.008814</td>\n",
       "      <td>0.992224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.009004</td>\n",
       "      <td>0.992224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.009166</td>\n",
       "      <td>0.992224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.009228</td>\n",
       "      <td>0.992224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.009325</td>\n",
       "      <td>0.992224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.009383</td>\n",
       "      <td>0.992224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.009427</td>\n",
       "      <td>0.992224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.009456</td>\n",
       "      <td>0.992224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.009479</td>\n",
       "      <td>0.992224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.009492</td>\n",
       "      <td>0.992224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.009494</td>\n",
       "      <td>0.992224</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1470, training_loss=0.003379223146000687, metrics={'train_runtime': 995.8273, 'train_samples_per_second': 11.719, 'train_steps_per_second': 1.476, 'total_flos': 2803818118030440.0, 'train_loss': 0.003379223146000687, 'epoch': 30.0})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_collator = DataCollatorForTokenClassification(tokenizer)\n",
    "\n",
    "trainer = WeightedTrainer(\n",
    "    model=model,\n",
    "    args=training_arguments,\n",
    "    train_dataset=tokenized_dataset_dict[\"train\"],\n",
    "    eval_dataset=tokenized_dataset_dict[\"validation\"],\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    "    processing_class=tokenizer,\n",
    ")\n",
    "trainer.train()\n",
    "# trainer.push_to_hub(commit_message=\"Training complete\", token=os.environ['HF_TOKEN'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc855b8f",
   "metadata": {},
   "source": [
    "### Inference\n",
    "\n",
    "Here just a basic test. For more complete inference examples, please see the inference notebooks:\n",
    "\n",
    "1. colabs/sentence_splitter_out_of_domain_eval_discriminative.ipynb\n",
    "2. colabs/sentence_splitter_out_of_domain_test_discriminative.ipynb\n",
    "3. colabs/sentence_splitter_out_of_domain_test_generative.ipynb\n",
    "\n",
    "Define an inference pipeline using the model deployed on the Hub."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "591fe39a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    }
   ],
   "source": [
    "model_checkpoint = \"fax4ever/\" + trained_model_name\n",
    "inference_pipeline = pipeline(\"token-classification\", model=model_checkpoint, \n",
    "                              aggregation_strategy=\"simple\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea92a4dc",
   "metadata": {},
   "source": [
    "Then pass any text to it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9de28848",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'entity_group': 'LABEL_0',\n",
       "  'score': np.float32(0.9991683),\n",
       "  'word': 'Non era un legno di lusso, ma un semplice pezzo da catasta, di quelli che d’inverno si mettono nelle stufe e nei caminetti per accendere il fuoco e per riscaldare le stanze',\n",
       "  'start': 0,\n",
       "  'end': 172},\n",
       " {'entity_group': 'LABEL_1',\n",
       "  'score': np.float32(0.99892277),\n",
       "  'word': '.',\n",
       "  'start': 172,\n",
       "  'end': 173},\n",
       " {'entity_group': 'LABEL_0',\n",
       "  'score': np.float32(0.9989502),\n",
       "  'word': ' Non so come andasse, ma il fatto gli è che un bel giorno questo pezzo di legno capitò nella bottega di un vecchio falegname, il quale aveva nome mastr’Antonio, se non che tutti lo chiamavano maestro Ciliegia, per via della punta del suo naso, che era sempre lustra e paonazza, come una ciliegia matura',\n",
       "  'start': 173,\n",
       "  'end': 475},\n",
       " {'entity_group': 'LABEL_1',\n",
       "  'score': np.float32(0.9999937),\n",
       "  'word': '.',\n",
       "  'start': 475,\n",
       "  'end': 476},\n",
       " {'entity_group': 'LABEL_0',\n",
       "  'score': np.float32(0.9988344),\n",
       "  'word': ' Appena maestro Ciliegia ebbe visto quel pezzo di legno, si rallegrò tutto; e dandosi una fregatina di mani per la contentezza, borbottò a mezza voce: \"Questo legno è capitato a tempo; voglio servirmene per fare una gamba di tavolino',\n",
       "  'start': 476,\n",
       "  'end': 709},\n",
       " {'entity_group': 'LABEL_1',\n",
       "  'score': np.float32(0.85268927),\n",
       "  'word': '.\"',\n",
       "  'start': 709,\n",
       "  'end': 711},\n",
       " {'entity_group': 'LABEL_0',\n",
       "  'score': np.float32(0.88223577),\n",
       "  'word': ' ',\n",
       "  'start': 711,\n",
       "  'end': 712}]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"\"\"Non era un legno di lusso, ma un semplice pezzo\n",
    "da catasta, di quelli che d’inverno si mettono nelle\n",
    "stufe e nei caminetti per accendere il fuoco e per riscaldare le stanze.\n",
    "Non so come andasse, ma il fatto gli è che un bel\n",
    "giorno questo pezzo di legno capitò nella bottega\n",
    "di un vecchio falegname, il quale aveva nome mastr’Antonio, se non che tutti lo chiamavano maestro\n",
    "Ciliegia, per via della punta del suo naso, che era\n",
    "sempre lustra e paonazza, come una ciliegia matura.\n",
    "Appena maestro Ciliegia ebbe visto quel pezzo di\n",
    "legno, si rallegrò tutto; e dandosi una fregatina di\n",
    "mani per la contentezza, borbottò a mezza voce:\n",
    "\"Questo legno è capitato a tempo; voglio servirmene per fare una gamba di tavolino.\" \n",
    "\"\"\"\n",
    "text = text.splitlines()\n",
    "text = \" \".join(text)\n",
    "\n",
    "inference_pipeline(text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
