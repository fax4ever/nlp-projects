{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3ab06da8",
   "metadata": {},
   "source": [
    "# Sentence splitter using an embedding model\n",
    "\n",
    "Install the required libraries in your virtual environment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceba93cf-d562-40aa-9e77-b826fe0b3045",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --upgrade pip\n",
    "!pip install torch numpy pandas datasets jupyter transformers[torch] evaluate seqeval"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ffd513f",
   "metadata": {},
   "source": [
    "Import all required libraries.\n",
    "\n",
    "We do this first to fail fast in case additional packages need to be installed in the virtual environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1f0e909-635d-4953-b6f0-1db100b79730",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from datasets import Dataset, DatasetDict, load_dataset\n",
    "from transformers import (AutoTokenizer, AutoModelForTokenClassification, DataCollatorForTokenClassification, \n",
    "                          TrainingArguments, Trainer, pipeline)\n",
    "from typing import Union, Any, Optional\n",
    "import evaluate\n",
    "from typing import Iterable, List"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6713e6e",
   "metadata": {},
   "source": [
    "Verify that a hardware accelerator is available.\n",
    "\n",
    "This notebook requires a GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48b4a80d-c9a5-4949-b7d0-6dac672c45bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['HF_TOKEN'] = 'PUT_YOUR_TOKEN_HERE'\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "839d5b93",
   "metadata": {},
   "source": [
    "Before proceeding, make the run as deterministic as possible:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0c03d87",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed=777, total_determinism=False):\n",
    "    seed = seed\n",
    "    torch.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    if total_determinism:\n",
    "        torch.use_deterministic_algorithms(True)\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "set_seed() # Set the seed for reproducibility -- use_deterministic_algorithms can make training slower :("
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22155736",
   "metadata": {},
   "source": [
    "## Part one: Create the dataset\n",
    "\n",
    "In this section, we create a standard Hugging Face dataset from the CSV files: `data/manzoni_dev_tokens.csv` and `data/manzoni_train_tokens.csv`.\n",
    "\n",
    "The output will be available at [fax4ever/manzoni-192](https://huggingface.co/datasets/fax4ever/manzoni-192).\n",
    "\n",
    "## Our first hyperparameter\n",
    "\n",
    "The original CSV files contain text that must be split into portions that can be passed to the encoder model. Typically, the maximum number of tokens for encoder models is 512 (e.g., BERT).\n",
    "Since each word can produce one or more tokens, a simple strategy would be to split texts to use the maximum number of tokens. This is not always optimal.\n",
    "Therefore, the number of words per input becomes our first hyperparameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "357c61f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "SIZE = 192 # Number of words to put on each input of the encoder model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "737f2acb",
   "metadata": {},
   "source": [
    "In the following code, we create the dataset and push it to the Hub.\n",
    "\n",
    "Publishing to the Hugging Face Hub allows us to use standard APIs‚Äîone benefit of open standards."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8daa7d2e-00af-41b7-b24f-99065b5b59e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_into_sequences(df, seq_len=SIZE):\n",
    "    tokens = df['token'].tolist()\n",
    "    labels = df['label'].tolist()\n",
    "    \n",
    "    # Group into sequences of seq_len\n",
    "    token_seqs = [tokens[i:i+seq_len] for i in range(0, len(tokens), seq_len) if len(tokens[i:i+seq_len]) == seq_len]\n",
    "    label_seqs = [labels[i:i+seq_len] for i in range(0, len(labels), seq_len) if len(labels[i:i+seq_len]) == seq_len]\n",
    "    \n",
    "    return {'tokens': token_seqs, 'labels': label_seqs}\n",
    "\n",
    "\n",
    "train = pd.read_csv(\"../data/manzoni_train_tokens.csv\")  # token,label\n",
    "validation = pd.read_csv(\"../data/manzoni_dev_tokens.csv\")  # token,label\n",
    "\n",
    "# Group into sequences of SIZE\n",
    "train_grouped = group_into_sequences(train)\n",
    "validation_grouped = group_into_sequences(validation)\n",
    "\n",
    "print(f\"Train: {len(train_grouped['tokens'])} sequences of {SIZE} tokens each\")\n",
    "print(f\"Validation: {len(validation_grouped['tokens'])} sequences of {SIZE} tokens each\")\n",
    "\n",
    "train_dataset = Dataset.from_dict(train_grouped)\n",
    "validation_dataset = Dataset.from_dict(validation_grouped)\n",
    "\n",
    "dataset_dict = DatasetDict({\n",
    "    'train': train_dataset,\n",
    "    'validation': validation_dataset  # Using 'validation' as the standard name\n",
    "})\n",
    "dataset_dict.push_to_hub(f\"fax4ever/manzoni-{SIZE}\", token=os.getenv(\"HF_TOKEN\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4a56efa",
   "metadata": {},
   "source": [
    "Alternatively, simply load the dataset from Hugging Face:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7c18589",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dict = load_dataset(f\"fax4ever/manzoni-{SIZE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9e4cce7",
   "metadata": {},
   "source": [
    "## Part two: Tokenize the dataset\n",
    "\n",
    "During tokenization, each word in an input may become one or more tokens.\n",
    "First, define some constants to reflect the convention in the CSV files. A label of 1 denotes the end (and thus beginning of a new sentence); 0 is used otherwise. Special tokens denoting start and end of sequences are labeled with 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5affc173",
   "metadata": {},
   "outputs": [],
   "source": [
    "END_OF_SENTENCE = 1\n",
    "NOT_END_OF_SENTENCE = 0\n",
    "LABEL_FOR_START_END_OF_SEQUENCE = NOT_END_OF_SENTENCE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "428c79d8",
   "metadata": {},
   "source": [
    "Choose a base embedding model to classify tokens as 0 or 1 (`num_labels=2`).\n",
    "\n",
    "Since the dataset is in Italian, consider multilingual models or models trained on Italian corpora:\n",
    "\n",
    "1. üöÄ ModernBERT-base-ita (most recent ‚Äì Dec 2024)\n",
    "   - `DeepMount00/ModernBERT-base-ita`\n",
    "\n",
    "2. üáÆüáπ Italian BERT XXL (most established)\n",
    "   - `dbmdz/bert-base-italian-xxl-cased`\n",
    "\n",
    "3. üåç XLM-RoBERTa (best multilingual)\n",
    "   - `FacebookAI/xlm-roberta-base`\n",
    "   - `FacebookAI/xlm-roberta-large`\n",
    "\n",
    "4. üî¨ Italian ELECTRA (alternative architecture)\n",
    "   - `dbmdz/electra-base-italian-xxl-cased-discriminator`\n",
    "\n",
    "Because we classify tokens rather than whole sequences, we use `AutoModelForTokenClassification` instead of `AutoModelForSequenceClassification`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d120457",
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING_MODEL = \"bert-base-cased\"\n",
    "\n",
    "model = AutoModelForTokenClassification.from_pretrained(EMBEDDING_MODEL, num_labels=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "049da04b",
   "metadata": {},
   "source": [
    "The original dataset provides labels for each word. When we tokenize the texts, we need to align the labels to the generated tokens.\n",
    "We keep label 1 for the first token of any word labeled 1 and use 0 for all other tokens. This preserves the original count of 1s per input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ab24b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(EMBEDDING_MODEL)\n",
    "\n",
    "def tokenize_and_align_labels(items):\n",
    "    tokenized_inputs = tokenizer(\n",
    "        items[\"tokens\"], is_split_into_words=True\n",
    "    )\n",
    "\n",
    "    all_labels = items[\"labels\"]\n",
    "    new_labels = []\n",
    "    for i, labels in enumerate(all_labels):\n",
    "        word_ids = tokenized_inputs.word_ids(i)\n",
    "        new_labels.append(align_labels_with_tokens(labels, word_ids))\n",
    "\n",
    "    tokenized_inputs[\"labels\"] = new_labels\n",
    "    return tokenized_inputs\n",
    "\n",
    "def align_labels_with_tokens(labels, word_ids):\n",
    "    new_labels = []\n",
    "    current_word = None\n",
    "    for word_id in word_ids:\n",
    "        if word_id != current_word:\n",
    "            # Start of a new word!\n",
    "            current_word = word_id\n",
    "            label = LABEL_FOR_START_END_OF_SEQUENCE if word_id is None else labels[word_id]\n",
    "            new_labels.append(label)\n",
    "        else:\n",
    "            # Treat the same word never as end of sentence\n",
    "            new_labels.append(NOT_END_OF_SENTENCE)\n",
    "    return new_labels\n",
    "\n",
    "tokenized_dataset_dict = dataset_dict.map(\n",
    "    tokenize_and_align_labels,\n",
    "    batched=True,\n",
    "    remove_columns=dataset_dict[\"train\"].column_names,\n",
    "    batch_size=128,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0741f4c7",
   "metadata": {},
   "source": [
    "## Part three: Training\n",
    "\n",
    "The dataset is highly imbalanced: most labels are 0 and few are 1. Accuracy is not a suitable metric here‚Äîfor example, predicting only 0 yields high accuracy.\n",
    "\n",
    "We therefore select the best model by F1 on the validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f87d34bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# as naming convention we use the embedding model name + \"-sentence-splitter\"\n",
    "# in this way we can easily identify the model we used to train the sentence splitter\n",
    "trained_model_name = EMBEDDING_MODEL + \"-sentence-splitter\"\n",
    "\n",
    "training_arguments = TrainingArguments(\n",
    "    trained_model_name,\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    "    push_to_hub=True,\n",
    "    hub_token=os.environ['HF_TOKEN'],\n",
    "    load_best_model_at_end=True, # Stop training when F1 stops improving\n",
    "    metric_for_best_model=\"f1\" # Of course on the validation set\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4e8b113",
   "metadata": {},
   "source": [
    "We also use a weighted cross‚Äëentropy loss during training.\n",
    "Misclassifying class 1 (end of sentence) is penalized 30√ó more than class 0. The weight (30) is another hyperparameter, motivated by the label distribution (‚âà96.7% class 0 vs ‚âà3.3% class 1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a83162fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WeightedTrainer(Trainer):\n",
    "    def compute_loss(self, model: nn.Module, inputs: dict[str, Union[torch.Tensor, Any]], return_outputs: bool = False, num_items_in_batch: Optional[torch.Tensor] = None):\n",
    "        labels = inputs.pop(\"labels\")\n",
    "        # forward pass\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.get(\"logits\")\n",
    "        # compute custom loss for 2 labels with different weights\n",
    "        # Simple class weights: give sentence endings 30x more importance\n",
    "        # Based on your data: 96.7% class 0, 3.3% class 1 ‚Üí ~30:1 ratio\n",
    "        loss_fct = nn.CrossEntropyLoss(weight=torch.tensor([1.0, 30.0], device=model.device))\n",
    "        loss = loss_fct(logits.view(-1, self.model.config.num_labels), labels.view(-1))\n",
    "        if num_items_in_batch is not None:\n",
    "            loss = loss / num_items_in_batch\n",
    "        return (loss, outputs) if return_outputs else loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7f53b9f",
   "metadata": {},
   "source": [
    "For each epoch, compute precision, recall, F1, and accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d7b2734",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loaded outside the compute_metrics function to avoid re-loading it at each epoch\n",
    "metric = evaluate.load(\"seqeval\")\n",
    "\n",
    "def map_nested_ints_to_strings(values: Iterable[Iterable[int]]) -> List[List[str]]:\n",
    "    return [\n",
    "        [str(item) for item in inner_iter]\n",
    "        for inner_iter in values\n",
    "    ]\n",
    "\n",
    "def compute_metrics(eval_preds):\n",
    "    logits, labels = eval_preds\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "\n",
    "    all_metrics = metric.compute(predictions=map_nested_ints_to_strings(predictions), references=map_nested_ints_to_strings(labels))\n",
    "    return {\n",
    "        \"precision\": all_metrics[\"overall_precision\"],\n",
    "        \"recall\": all_metrics[\"overall_recall\"],\n",
    "        \"f1\": all_metrics[\"overall_f1\"],\n",
    "        \"accuracy\": all_metrics[\"overall_accuracy\"],\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9fdba42",
   "metadata": {},
   "source": [
    "Push all epoch metrics and the final trained model to the Hugging Face Hub so the model can be used for inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a290771",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorForTokenClassification(tokenizer)\n",
    "\n",
    "trainer = WeightedTrainer (\n",
    "    model=model,\n",
    "    args=training_arguments,\n",
    "    train_dataset=tokenized_dataset_dict[\"train\"],\n",
    "    eval_dataset=tokenized_dataset_dict[\"validation\"],\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    "    processing_class=tokenizer,\n",
    ")\n",
    "trainer.train()\n",
    "trainer.push_to_hub(commit_message=\"Training complete\", token=os.environ['HF_TOKEN'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc855b8f",
   "metadata": {},
   "source": [
    "## Part four: Inference\n",
    "\n",
    "Define an inference pipeline using the model deployed on the Hub."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "591fe39a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_checkpoint = \"fax4ever/\" + trained_model_name\n",
    "inference_pipeline = pipeline(\"token-classification\", model=model_checkpoint, \n",
    "                              aggregation_strategy=\"simple\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea92a4dc",
   "metadata": {},
   "source": [
    "Then pass any text to it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9de28848",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"\n",
    "    Non era un legno di lusso, ma un semplice pezzo\n",
    "    da catasta, di quelli che d‚Äôinverno si mettono nelle\n",
    "    stufe e nei caminetti per accendere il fuoco e per riscaldare le stanze.\n",
    "    Non so come andasse, ma il fatto gli √® che un bel\n",
    "    giorno questo pezzo di legno capit√≤ nella bottega\n",
    "    di un vecchio falegname, il quale aveva nome mastr‚ÄôAntonio, se non che tutti lo chiamavano maestro\n",
    "    Ciliegia, per via della punta del suo naso, che era\n",
    "    sempre lustra e paonazza, come una ciliegia matura.\n",
    "    Appena maestro Ciliegia ebbe visto quel pezzo di\n",
    "    legno, si rallegr√≤ tutto; e dandosi una fregatina di\n",
    "    mani per la contentezza, borbott√≤ a mezza voce:\n",
    "    \"Questo legno √® capitato a tempo; voglio servirmene per fare una gamba di tavolino.\" \n",
    "\"\"\".rstrip()\n",
    "\n",
    "inference_pipeline(text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
